{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T20:33:35.799179Z",
     "start_time": "2020-11-12T20:33:35.788926Z"
    }
   },
   "source": [
    "# [Sentiment Analysis](https://www.kaggle.com/c/sentiment-analysis-pmr3508)\n",
    "\n",
    "[PMR3508](https://uspdigital.usp.br/jupiterweb/obterDisciplina?sgldis=PMR3508) - Machine Learning and Pattern Recognition\n",
    "\n",
    "Professor Fabio Gagliardi Cozman\n",
    "\n",
    "PMR3508-2020-83 - [Vitor Gratiere Torres](https://github.com/vitorgt/PMR3508)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment's goal is to tell whether an IMDb review is positive or negative (complementary).\n",
    "\n",
    "My analysis takes the following steps:\n",
    "\n",
    "1. [Import data and python modules](#1.-Import-data-and-python-modules) (Acquisition)\n",
    "1. [Preprocessing](#2.-Preprocessing)\n",
    "    1. [Clean text and vectorize](#2.1.-Clean-text-and-vectorize) (Preprocessing)\n",
    "    1. [Embed words](#2.2.-Embed-words) (Representation)\n",
    "1. [Modelling](#3.-Modelling)\n",
    "    1. [Models Definition and Hyperparameters Search](#3.1.-Models-Definition-and-Hyperparameters-Search)\n",
    "        1. [Logistic Regression](#3.1.1.-Logistic-Regression)\n",
    "        1. [K-nearest Neighbors](#3.1.2.-K-nearest-Neighbors)\n",
    "        1. [Multi-layer Perceptron - 1 Hidden Layer](#3.1.3.-Multi-layer-Perceptron---1-Hidden-Layer)\n",
    "        1. [Multi-layer Perceptron - 2 Hidden Layers](#3.1.4.-Multi-layer-Perceptron---2-Hidden-Layers)\n",
    "        1. [PyTorch Multi-layer Perceptron - 2 Hidden Layers](#3.1.5.-PyTorch-Multi-layer-Perceptron---2-Hidden-Layers)\n",
    "    1. [Metric Comparison](#3.2.-Metric-Comparison)\n",
    "1. [Submission](#4.-Submission)\n",
    "\n",
    "# 1. Import data and python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:50:22.983276Z",
     "start_time": "2020-12-06T03:50:21.249944Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import loguniform\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "# Text modules\n",
    "import re\n",
    "import string\n",
    "from ftfy import fix_text\n",
    "\n",
    "# Embeddings\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:50:24.115026Z",
     "start_time": "2020-12-06T03:50:22.987295Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (24984, 2)\n",
      "          positive\n",
      "count  24984.00000\n",
      "mean       0.49988\n",
      "std        0.50001\n",
      "min        0.00000\n",
      "25%        0.00000\n",
      "50%        0.00000\n",
      "75%        1.00000\n",
      "max        1.00000\n",
      "\n",
      "Test data shape: (12492, 2)\n",
      "           positive\n",
      "count  12492.000000\n",
      "mean       0.495037\n",
      "std        0.499995\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "\n",
      "Submission data shape: (12493, 1)\n",
      "                                                   review\n",
      "count                                               12493\n",
      "unique                                              12436\n",
      "top     Footprints is a very interesting movie that is...\n",
      "freq                                                    2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>Rock n' roll is a messy business and DiG! demo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>Hunky Geordie Robson Green is Owen Springer, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>It was easy for Sir Richard Attenborough to ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20369</th>\n",
       "      <td>Yes, this is one of THOSE movies, so terrible,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>This movie is incredibly realistic and I feel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  positive\n",
       "11369  Rock n' roll is a messy business and DiG! demo...         1\n",
       "6382   Hunky Geordie Robson Green is Owen Springer, a...         1\n",
       "8766   It was easy for Sir Richard Attenborough to ma...         1\n",
       "20369  Yes, this is one of THOSE movies, so terrible,...         0\n",
       "5205   This movie is incredibly realistic and I feel ...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XYtrain = pd.read_csv(\"sentiment-analysis-pmr3508/data_train.csv\")\n",
    "XYtest = pd.read_csv(\"sentiment-analysis-pmr3508/data_test1.csv\")\n",
    "Xsubmit = pd.read_csv(\"sentiment-analysis-pmr3508/data_test2_X.csv\")\n",
    "\n",
    "print(\"Training data shape:\", XYtrain.shape)\n",
    "print(XYtrain.describe())\n",
    "\n",
    "print(\"\\nTest data shape:\", XYtest.shape)\n",
    "print(XYtest.describe())\n",
    "\n",
    "print(\"\\nSubmission data shape:\", Xsubmit.shape)\n",
    "print(Xsubmit.describe())\n",
    "\n",
    "XYtrain.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing\n",
    "\n",
    "The nature of this dataset is different from previous, there might not be ```NAs```, ```NANs``` or ```Nulls```, this time we ought to notice duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:50:24.272491Z",
     "start_time": "2020-12-06T03:50:24.121936Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape initially: (24984, 2)\n",
      "Training data shape without duplicates: (24888, 2)\n",
      "\n",
      "Test data shape initially: (12492, 2)\n",
      "Test data shape without duplicates: (12441, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape initially:\", XYtrain.shape)\n",
    "XYtrain = XYtrain.drop_duplicates(keep=\"first\")\n",
    "print(\"Training data shape without duplicates:\", XYtrain.shape)\n",
    "\n",
    "print(\"\\nTest data shape initially:\", XYtest.shape)\n",
    "XYtest = XYtest.drop_duplicates(keep=\"first\")\n",
    "print(\"Test data shape without duplicates:\", XYtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:50:24.287007Z",
     "start_time": "2020-12-06T03:50:24.275441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (24888,) Ytrain (24888,)\n",
      "Xtest (12441,) Ytest (12441,)\n",
      "Xsubmit (12493,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = XYtrain.loc[:, \"review\"]\n",
    "Ytrain = XYtrain.loc[:, \"positive\"]\n",
    "\n",
    "Xtest = XYtest.loc[:, \"review\"]\n",
    "Ytest = XYtest.loc[:, \"positive\"]\n",
    "\n",
    "Xsubmit = Xsubmit.iloc[:, 0]\n",
    "\n",
    "del XYtrain\n",
    "del XYtest\n",
    "\n",
    "print(\"Xtrain\", Xtrain.shape, \"Ytrain\", Ytrain.shape)\n",
    "print(\"Xtest\", Xtest.shape, \"Ytest\", Ytest.shape)\n",
    "print(\"Xsubmit\", Xsubmit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are all ```pandas.Series``` now.\n",
    "\n",
    "## 2.1. Clean text and vectorize\n",
    "\n",
    "We were given the below function to clean and prepare the dataset. This is an important step dealing with NLP, we could make use of NLTK or spaCy, but we rather a manual approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:51:12.047641Z",
     "start_time": "2020-12-06T03:50:24.290655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14177    [i, didnt, enjoy, this, movie, at, allfor, one...\n",
      "17087    [im, starting, to, write, this, review, during...\n",
      "3717     [stanley, and, iris, show, the, triumph, of, t...\n",
      "Name: review, dtype: object\n",
      "7477     [i, have, been, wanting, to, see, this, since,...\n",
      "7643     [i, like, movies, that, show, real, people, am...\n",
      "12166    [there, have, been, some, great, television, m...\n",
      "Name: review, dtype: object\n",
      "11688    [the, <number>, s, were, overrun, by, all, tho...\n",
      "11757    [i, love, this, young, people, trapped, in, a,...\n",
      "537      [as, an, avid, gone, with, the, wind, fan, i, ...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def preptext(txt):\n",
    "    # removing tags\n",
    "    txt = txt.replace(\"<br />\", \" \")\n",
    "    # fixing Mojibakes (See https://pypi.org/project/ftfy/)\n",
    "    txt = fix_text(txt)\n",
    "    # converting case\n",
    "    txt = txt.lower()\n",
    "    # removing punctuation\n",
    "    txt = txt.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # removing hyphens\n",
    "    txt = txt.replace(\" — \", \" \")\n",
    "    # replacing digits with a tag\n",
    "    txt = re.sub(\"\\d+\", \" <number> \", txt)\n",
    "    # removing double spaces\n",
    "    txt = re.sub(\" +\", \" \", txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_split(data):\n",
    "    # let's apply this function to clean the dataset\n",
    "    data = data.apply(preptext)\n",
    "\n",
    "    # now I need a vector of words, I'll split those strings\n",
    "    data = data.apply(lambda x: x.split())\n",
    "\n",
    "    print(data.sample(3))\n",
    "    return data\n",
    "\n",
    "\n",
    "Xtrain = clean_split(Xtrain)\n",
    "Xtest = clean_split(Xtest)\n",
    "Xsubmit = clean_split(Xsubmit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Embed words\n",
    "\n",
    "It is a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension $f:\\; \\text{word} \\hookrightarrow \\mathbb{R}^{50}$.\n",
    "\n",
    "We'll use a pre-trained Doc2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:57:34.647484Z",
     "start_time": "2020-12-06T03:51:12.053580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Xtrain\n",
      "Xtrain shape: (24888, 50)\n",
      "Embedding Xtrain done in 199.1s\n",
      "\n",
      "Embedding Xtest\n",
      "Xtest shape: (12441, 50)\n",
      "Embedding Xtest done in 84.7s\n",
      "\n",
      "Embedding Xsubmit\n",
      "Xsubmit shape: (12493, 50)\n",
      "Embedding Xsubmit done in 97.7s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>-0.389007</td>\n",
       "      <td>-1.906648</td>\n",
       "      <td>0.083847</td>\n",
       "      <td>0.601308</td>\n",
       "      <td>-1.903552</td>\n",
       "      <td>1.436674</td>\n",
       "      <td>-0.111065</td>\n",
       "      <td>0.992137</td>\n",
       "      <td>-1.178109</td>\n",
       "      <td>-1.134489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365865</td>\n",
       "      <td>-0.257926</td>\n",
       "      <td>-1.978419</td>\n",
       "      <td>-0.264564</td>\n",
       "      <td>-0.235605</td>\n",
       "      <td>0.146907</td>\n",
       "      <td>-0.171853</td>\n",
       "      <td>-0.113333</td>\n",
       "      <td>-0.369105</td>\n",
       "      <td>0.213336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.650514</td>\n",
       "      <td>-1.132547</td>\n",
       "      <td>-0.726380</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>-0.450859</td>\n",
       "      <td>-0.095051</td>\n",
       "      <td>0.066853</td>\n",
       "      <td>-0.460648</td>\n",
       "      <td>0.349480</td>\n",
       "      <td>-0.882087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466829</td>\n",
       "      <td>-1.123515</td>\n",
       "      <td>0.117008</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>-0.206961</td>\n",
       "      <td>-0.576789</td>\n",
       "      <td>-0.197853</td>\n",
       "      <td>-0.341755</td>\n",
       "      <td>0.696647</td>\n",
       "      <td>-1.143242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>-0.063845</td>\n",
       "      <td>-0.122038</td>\n",
       "      <td>-1.091817</td>\n",
       "      <td>1.574319</td>\n",
       "      <td>0.432568</td>\n",
       "      <td>0.186428</td>\n",
       "      <td>-1.155819</td>\n",
       "      <td>-0.077032</td>\n",
       "      <td>-0.112485</td>\n",
       "      <td>0.720673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.413528</td>\n",
       "      <td>0.637412</td>\n",
       "      <td>0.067488</td>\n",
       "      <td>0.206915</td>\n",
       "      <td>-1.191482</td>\n",
       "      <td>-0.216786</td>\n",
       "      <td>0.352696</td>\n",
       "      <td>-1.397749</td>\n",
       "      <td>-0.363585</td>\n",
       "      <td>1.349430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17845</th>\n",
       "      <td>-0.706304</td>\n",
       "      <td>0.159149</td>\n",
       "      <td>-0.510835</td>\n",
       "      <td>-0.191042</td>\n",
       "      <td>-0.471920</td>\n",
       "      <td>-0.068397</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>-1.246378</td>\n",
       "      <td>-0.089533</td>\n",
       "      <td>1.793827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210131</td>\n",
       "      <td>-0.408126</td>\n",
       "      <td>-1.939433</td>\n",
       "      <td>-0.766466</td>\n",
       "      <td>1.586310</td>\n",
       "      <td>-0.604824</td>\n",
       "      <td>-0.154632</td>\n",
       "      <td>-0.068213</td>\n",
       "      <td>-0.409830</td>\n",
       "      <td>-1.208645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23523</th>\n",
       "      <td>-0.536427</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.024463</td>\n",
       "      <td>0.828699</td>\n",
       "      <td>0.303688</td>\n",
       "      <td>-0.334226</td>\n",
       "      <td>0.431376</td>\n",
       "      <td>-0.314037</td>\n",
       "      <td>-0.556991</td>\n",
       "      <td>-0.641372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329647</td>\n",
       "      <td>-0.803746</td>\n",
       "      <td>0.206624</td>\n",
       "      <td>0.371842</td>\n",
       "      <td>-0.856415</td>\n",
       "      <td>-1.156844</td>\n",
       "      <td>-0.259034</td>\n",
       "      <td>-0.114242</td>\n",
       "      <td>0.588103</td>\n",
       "      <td>0.373455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "1096  -0.389007 -1.906648  0.083847  0.601308 -1.903552  1.436674 -0.111065   \n",
       "197   -0.650514 -1.132547 -0.726380  0.003158 -0.450859 -0.095051  0.066853   \n",
       "11430 -0.063845 -0.122038 -1.091817  1.574319  0.432568  0.186428 -1.155819   \n",
       "17845 -0.706304  0.159149 -0.510835 -0.191042 -0.471920 -0.068397  0.996231   \n",
       "23523 -0.536427  0.590435  0.024463  0.828699  0.303688 -0.334226  0.431376   \n",
       "\n",
       "             7         8         9   ...        40        41        42  \\\n",
       "1096   0.992137 -1.178109 -1.134489  ... -0.365865 -0.257926 -1.978419   \n",
       "197   -0.460648  0.349480 -0.882087  ...  0.466829 -1.123515  0.117008   \n",
       "11430 -0.077032 -0.112485  0.720673  ...  1.413528  0.637412  0.067488   \n",
       "17845 -1.246378 -0.089533  1.793827  ...  0.210131 -0.408126 -1.939433   \n",
       "23523 -0.314037 -0.556991 -0.641372  ...  0.329647 -0.803746  0.206624   \n",
       "\n",
       "             43        44        45        46        47        48        49  \n",
       "1096  -0.264564 -0.235605  0.146907 -0.171853 -0.113333 -0.369105  0.213336  \n",
       "197    0.294727 -0.206961 -0.576789 -0.197853 -0.341755  0.696647 -1.143242  \n",
       "11430  0.206915 -1.191482 -0.216786  0.352696 -1.397749 -0.363585  1.349430  \n",
       "17845 -0.766466  1.586310 -0.604824 -0.154632 -0.068213 -0.409830 -1.208645  \n",
       "23523  0.371842 -0.856415 -1.156844 -0.259034 -0.114242  0.588103  0.373455  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v = Doc2Vec.load(\"sentiment-analysis-pmr3508/doc2vec\")\n",
    "\n",
    "print(\"Embedding Xtrain\")\n",
    "srt = time.perf_counter()\n",
    "Xtrain = Xtrain.apply(d2v.infer_vector, steps=20)\n",
    "Xtrain = pd.DataFrame(Xtrain.to_list())\n",
    "end = time.perf_counter()\n",
    "print(\"Xtrain shape:\", Xtrain.shape)\n",
    "print(f\"Embedding Xtrain done in {end - srt:.1f}s\\n\")\n",
    "\n",
    "print(\"Embedding Xtest\")\n",
    "srt = time.perf_counter()\n",
    "Xtest = Xtest.apply(d2v.infer_vector, steps=20)\n",
    "Xtest = pd.DataFrame(Xtest.to_list())\n",
    "end = time.perf_counter()\n",
    "print(\"Xtest shape:\", Xtest.shape)\n",
    "print(f\"Embedding Xtest done in {end - srt:.1f}s\\n\")\n",
    "\n",
    "print(\"Embedding Xsubmit\")\n",
    "srt = time.perf_counter()\n",
    "Xsubmit = Xsubmit.apply(d2v.infer_vector, steps=20)\n",
    "Xsubmit = pd.DataFrame(Xsubmit.to_list())\n",
    "end = time.perf_counter()\n",
    "print(\"Xsubmit shape:\", Xsubmit.shape)\n",
    "print(f\"Embedding Xsubmit done in {end - srt:.1f}s\\n\")\n",
    "\n",
    "Xtrain.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is ready!\n",
    "\n",
    "# 3. Modelling\n",
    "\n",
    "## 3.1. Models Definition and Hyperparameters Search\n",
    "\n",
    "Now, using ```sklearn.model_selection.RandomizedSearchCV```, we'll search for the best hyperparameters for each classifier maximizing Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "### 3.1.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T03:57:53.803692Z",
     "start_time": "2020-12-06T03:57:34.650127Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 0.5145454545454545} 0.8817682434170644\n",
      "CPU times: user 834 ms, sys: 391 ms, total: 1.23 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Model definition\n",
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "# Hyperparameters\n",
    "logreg_hp = dict(\n",
    "    # Inverse of regularization strength; must be a positive float.\n",
    "    # Like in support vector machines, smaller values specify\n",
    "    # stronger regularization.\n",
    "    C=np.linspace(0.01, 10, 100),\n",
    "    # Used to specify the norm used in the penalization.\n",
    "    penalty=[\"l1\", \"l2\"],\n",
    ")\n",
    "\n",
    "# Research\n",
    "logreg_researcher = RandomizedSearchCV(\n",
    "    logreg,\n",
    "    logreg_hp,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=2,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "logreg_results = logreg_researcher.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Result\n",
    "print(logreg_results.best_params_, logreg_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:17:10.557705Z",
     "start_time": "2020-12-06T03:57:53.805977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 207} 0.8647431582264684\n",
      "CPU times: user 759 ms, sys: 82 ms, total: 841 ms\n",
      "Wall time: 19min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Model definition\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Hyperparameters\n",
    "knn_hp = dict(\n",
    "    # Number of neighbors to use.\n",
    "    n_neighbors=np.arange(151, 210, 1),\n",
    ")\n",
    "\n",
    "# Research\n",
    "knn_researcher = RandomizedSearchCV(\n",
    "    knn,\n",
    "    knn_hp,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=2,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "knn_results = knn_researcher.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Result\n",
    "print(knn_results.best_params_, knn_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Multi-layer Perceptron - 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:20:40.814677Z",
     "start_time": "2020-12-06T04:17:10.560841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 5.182449896642826e-06, 'hidden_layer_sizes': (256,)} 0.8895135969653997\n",
      "CPU times: user 28.7 s, sys: 1min 11s, total: 1min 39s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Model definition\n",
    "mlp_1h = MLPClassifier(early_stopping=True)\n",
    "\n",
    "# Hyperparameters\n",
    "mlp_1h_hp = dict(\n",
    "    # The ith element represents the number of neurons in the ith\n",
    "    # hidden layer.\n",
    "    hidden_layer_sizes=[(2 ** i,) for i in np.arange(6, 12)],\n",
    "    # L2 penalty (regularization term) parameter.\n",
    "    alpha=loguniform(0.000001, 0.1),\n",
    ")\n",
    "\n",
    "# Research\n",
    "mlp_1h_researcher = RandomizedSearchCV(\n",
    "    mlp_1h,\n",
    "    mlp_1h_hp,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=2,\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "mlp_1h_results = mlp_1h_researcher.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Result\n",
    "print(mlp_1h_results.best_params_, mlp_1h_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. Multi-layer Perceptron - 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:26:03.274784Z",
     "start_time": "2020-12-06T04:20:40.821395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 4.485364848374194e-06, 'hidden_layer_sizes': (256, 64)} 0.8896468326732914\n",
      "CPU times: user 17.9 s, sys: 24.7 s, total: 42.6 s\n",
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Model definition\n",
    "mlp_2h = MLPClassifier(early_stopping=True)\n",
    "\n",
    "# Hyperparameters\n",
    "mlp_2h_hp = dict(\n",
    "    # The ith element represents the number of neurons in the ith\n",
    "    # hidden layer.\n",
    "    hidden_layer_sizes=[\n",
    "        (2 ** i, 2 ** j)\n",
    "        for j in np.arange(6, 10)\n",
    "        for i in np.arange(6, 10)\n",
    "    ],\n",
    "    # L2 penalty (regularization term) parameter.\n",
    "    alpha=loguniform(0.000001, 0.1),\n",
    ")\n",
    "\n",
    "# Research\n",
    "mlp_2h_researcher = RandomizedSearchCV(\n",
    "    mlp_2h,\n",
    "    mlp_2h_hp,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=2,\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "mlp_2h_results = mlp_2h_researcher.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Result\n",
    "print(mlp_2h_results.best_params_, mlp_2h_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. PyTorch Multi-layer Perceptron - 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:54:16.123353Z",
     "start_time": "2020-12-06T04:26:03.280342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('module__hidden1_dim', 1476), ('module__hidden2_dim', 518), ('module__p', 0.47278526786037134), ('optimizer__weight_decay', 6.087811802931341e-09)]) 0.8934223721123139\n",
      "CPU times: user 5min 7s, sys: 1min 56s, total: 7min 4s\n",
      "Wall time: 28min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Model definition\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, hidden1_dim=512, hidden2_dim=64, p=0.25):\n",
    "        super(MLPNet, self).__init__()\n",
    "\n",
    "        # 50 -> hidden1_dim -> hidden2_dim -> 2\n",
    "        self.fc1 = nn.Linear(50, hidden1_dim)\n",
    "        self.fc2 = nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.fc3 = nn.Linear(hidden2_dim, 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        fc_out = F.relu(self.fc1(X))\n",
    "        fc_out = self.dropout(fc_out)\n",
    "\n",
    "        fc_out = F.relu(self.fc2(fc_out))\n",
    "        fc_out = self.dropout(fc_out)\n",
    "\n",
    "        fc_out = self.fc3(fc_out)\n",
    "        soft_out = F.softmax(fc_out, dim=-1)\n",
    "\n",
    "        return soft_out\n",
    "\n",
    "\n",
    "# Model definition\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_2h = NeuralNetClassifier(\n",
    "    MLPNet().to(device),\n",
    "    max_epochs=20,\n",
    "    lr=1e-4,\n",
    "    optimizer=optim.Adam,\n",
    "    optimizer__weight_decay=1e-4,\n",
    "    train_split=False,\n",
    "    verbose=0,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "# Hyperparameters\n",
    "torch_2h_hp = dict(\n",
    "    module__hidden1_dim=Integer(256, 2048),\n",
    "    module__hidden2_dim=Integer(64, 1024),\n",
    "    module__p=Real(0.1, 0.75, prior=\"uniform\"),\n",
    "    optimizer__weight_decay=Real(1e-10, 1e-2, prior=\"log-uniform\"),\n",
    ")\n",
    "\n",
    "# Research\n",
    "torch_2h_researcher = BayesSearchCV(\n",
    "    torch_2h,\n",
    "    torch_2h_hp,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=2,\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "torch_2h_results = torch_2h_researcher.fit(\n",
    "    Xtrain.to_numpy(np.float32), Ytrain.to_numpy(np.int64)\n",
    ")\n",
    "\n",
    "# Result\n",
    "print(torch_2h_results.best_params_, torch_2h_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Metric Comparison\n",
    "\n",
    "Based on ```Test``` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:55:03.424000Z",
     "start_time": "2020-12-06T04:54:16.126502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.88221\n",
      "It took 0.0s\n",
      "\n",
      "K-nearest Neighbors: 0.86408\n",
      "It took 46.6s\n",
      "\n",
      "Multi-layer Perceptron 1 Hidden: 0.89149\n",
      "It took 0.0s\n",
      "\n",
      "Multi-layer Perceptron 2 Hidden: 0.88714\n",
      "It took 0.1s\n",
      "\n",
      "PyTorch Multi-layer Perceptron 2 Hidden: 0.89708\n",
      "It took 0.5s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srt = time.perf_counter()\n",
    "logreg_test_score = roc_auc_score(\n",
    "    Ytest, logreg_results.predict_proba(Xtest)[:, 1]\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\"Logistic Regression: {logreg_test_score:.5f}\")\n",
    "print(f\"It took {end - srt:.1f}s\\n\")\n",
    "\n",
    "srt = time.perf_counter()\n",
    "knn_test_score = roc_auc_score(\n",
    "    Ytest, knn_results.predict_proba(Xtest)[:, 1]\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\"K-nearest Neighbors: {knn_test_score:.5f}\")\n",
    "print(f\"It took {end - srt:.1f}s\\n\")\n",
    "\n",
    "srt = time.perf_counter()\n",
    "mlp_1h_test_score = roc_auc_score(\n",
    "    Ytest, mlp_1h_results.predict_proba(Xtest)[:, 1]\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\"Multi-layer Perceptron 1 Hidden: {mlp_1h_test_score:.5f}\")\n",
    "print(f\"It took {end - srt:.1f}s\\n\")\n",
    "\n",
    "srt = time.perf_counter()\n",
    "mlp_2h_test_score = roc_auc_score(\n",
    "    Ytest, mlp_2h_results.predict_proba(Xtest)[:, 1]\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\"Multi-layer Perceptron 2 Hidden: {mlp_2h_test_score:.5f}\")\n",
    "print(f\"It took {end - srt:.1f}s\\n\")\n",
    "\n",
    "srt = time.perf_counter()\n",
    "torch_2h_test_score = roc_auc_score(\n",
    "    Ytest,\n",
    "    torch_2h_results.predict_proba(Xtest.to_numpy(np.float32))[:, 1],\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(\n",
    "    f\"PyTorch Multi-layer Perceptron 2 Hidden: {torch_2h_test_score:.5f}\"\n",
    ")\n",
    "print(f\"It took {end - srt:.1f}s\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:55:03.888098Z",
     "start_time": "2020-12-06T04:55:03.425984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.490494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>0.123713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>0.316657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12490</th>\n",
       "      <td>0.005438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>0.099295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>0.428212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12493 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       positive\n",
       "0      0.000494\n",
       "1      0.490494\n",
       "2      0.002213\n",
       "3      0.136872\n",
       "4      0.023931\n",
       "...         ...\n",
       "12488  0.123713\n",
       "12489  0.316657\n",
       "12490  0.005438\n",
       "12491  0.099295\n",
       "12492  0.428212\n",
       "\n",
       "[12493 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ysubmit = torch_2h_results.predict_proba(Xsubmit.to_numpy(np.float32))[:, 1]\n",
    "Ysubmit = pd.DataFrame({\"positive\": Ysubmit})\n",
    "Ysubmit.to_csv(\"submission.csv\", index=True, index_label=\"Id\")\n",
    "Ysubmit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
